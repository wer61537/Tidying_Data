---
title: "Codebook"
author: "Bill Rowe"
date: "April 23, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Background on the UCI dataset

The [*Human Activity Recognition Using Smartphones Data Set*] data for this project is from the [UCI Machine Learning](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) repository.  The data is from Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz,  *Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine* presented at the International Workshop of Ambient Assisted Living (IWAAL 2012).
   
A modified Samsung Galaxy II was used to conduct exercise experiments with thirty volunteers ranging in age from 19-48 years.  Each volunteer performed six activities: walking, walking upstairs, walking downstairs, sitting, standing and laying.  Each activity was monitored withe the smartphone's embedded accelerometer and gyroscope at 50HZ.  Videos of the experiment were recorded and annotated manually.

The dataset set has 10,299 observations with 563 variables. Variables are created from gravity and accelerometer readings for body and gravity at three orientations (x, y, z) for each activity.  Statistics for each combination are calculated.  The statistics were mean(), std(), mad() or median absolute deviation, max(), min(), sma() or signal magnitude area, energy(), iqr() or Interquartile range, entropy(), arCoeff() or autoregression coefficients with Burg order equal to 4, correlation(), maxInds() or the index of the frequency component with largest magnitude, meanFreq() or Weighted average of the frequency components used to obtain a mean frequency, skewness(), kurtosis(), bandsEnergy() or energy of a frequency interval within the 64 bins of the FFT of each window and angle() or angle between some vectors.  Each variable was normalized (bound to [-1, 1]).

The original data was partitioned, randomly, to create two datasets: training and test.  The training set had 70% of the data and the test 30%.  

### Preparation of Tidied Dataset

The test (X_test.txt, y_test.txt) and training (X_train.txt, y_train.txt) data are combined with their respective subject ids (subject_test.txt and subject_train.txt).  After the test and training datasets are merged, the features (variable names) and activities ("walking"", etc.),  

### Extract mean and standard deviation variables

Only the mean and standard deviation (std) are needed from the merged dataset are needed for the project so these are extracted.

### Add activity and feature names to label variables appropriately and descriptively

The integers representing activities are replaced with their names in the activity_labels.txt file and variable names with values from the features.txt.  

### Make variable names more descriptive

Some of the variable names begin with "t" or "f".  "t" represents "time" and "f" represents "frequency".  Other variables are mislabeled like "BodyBody" and have inconsistent use of dashes rather than underscores or brackets and parentheses.  Spell out "Acc", "Gyro", "Mag".

### Calculate the mean and standard deviation of the numeric variables by subject and activity

For each subject adnd activity combination in the merged, labled dataset the mean and standard deviation for each numeric variable.

### Export the tidied data set

Finally, create the tidy dataset where activities and features are labeled and features are averaged by subject and activity.  This dataset has 10,299 observations and 81 variables arrange as subject (1...30), activity (walking, walking upstairs, walking downstairs, sitting, standing and laying) and a 79-feature vector.  The tidied data set can be found at [GitHub](https://github.com/wer61537/Tidying_Data/blob/master/tidied_data.csv).  

